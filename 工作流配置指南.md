# 工作流数据转换和迭代配置指南

## 1. 添加数据转换节点

在SQL执行节点之后，添加一个代码执行节点：

### 节点配置
```yaml
- data:
    code: |
      import json
      import re

      def main(response_body: str) -> dict:
          """
          将数据库查询结果转换为可迭代的数组格式
          """
          
          try:
              # 解析输入的JSON数据
              data = json.loads(response_body)
              text_content = data.get("text", "")
              
              # 提取JSON对象列表
              titles_data = []
              
              if text_content:
                  # 分割文本，去除Schema信息
                  lines = text_content.split('\n')
                  
                  for line in lines:
                      line = line.strip()
                      # 跳过Schema行和空行
                      if not line or line.startswith("Schema:"):
                          continue
                      
                      # 尝试解析每行的JSON
                      try:
                          json_obj = json.loads(line)
                          if isinstance(json_obj, dict) and "title" in json_obj:
                              titles_data.append({
                                  "title": json_obj.get("title", ""),
                                  "post_id": json_obj.get("post_id", ""),
                                  "author_name": json_obj.get("author_name", ""),
                                  "classification": json_obj.get("classification", ""),
                                  "created_at": json_obj.get("created_at", ""),
                                  "index": len(titles_data) + 1
                              })
                      except json.JSONDecodeError:
                          continue
              
              result = {
                  "titles_array": titles_data,
                  "total_count": len(titles_data),
                  "status": "success" if titles_data else "no_data",
                  "processing_ready": True
              }
              
              return result
              
          except Exception as e:
              return {
                  "titles_array": [],
                  "total_count": 0,
                  "status": "error",
                  "error_message": str(e),
                  "processing_ready": False
              }
    code_language: python3
    outputs:
      titles_array:
        type: array
      total_count:
        type: number
      status:
        type: string
      processing_ready:
        type: boolean
    title: 数据转换处理
    type: code
    variables:
    - value_selector:
      - '1758258411694'  # 上游SQL执行节点ID
      - text
      value_type: string
      variable: response_body
```

## 2. 修改后续处理节点

将"帖子详细内容获取"节点的提示词修改为支持批量处理：

### 新的LLM提示词
```
你是一个小红书帖子批量分析的API参数生成器。仅输出严格的JSON格式，不包含任何解释、代码块标记或其他文字。

## 输入信息
标题数组数据：{{#[数据转换节点ID].titles_array#}}
当前会话ID：{{#conversation.sandbox_persistent_id#}}

## 任务说明
为数组中的每个帖子标题生成完整的浏览器操作序列，实现批量自动化处理。

## 输出格式
{
  "batch_operations": [
    {
      "title": "{{标题1}}",
      "post_id": "{{帖子ID1}}",
      "author_name": "{{作者名1}}",
      "sequence": 1,
      "operations": [
        {
          "action": "click_selector",
          "params": {
            "selector": "input[placeholder*='搜索'], .search-input"
          },
          "description": "点击搜索框"
        },
        {
          "action": "type_text",
          "params": {
            "selector": "input[placeholder*='搜索'], .search-input",
            "text": "{{标题1}}"
          },
          "description": "输入搜索关键词"
        },
        {
          "action": "click_selector",
          "params": {
            "selector": ".search-icon, [class*='search-btn'], button[type='submit']"
          },
          "description": "执行搜索"
        },
        {
          "action": "xiaohongshu_auto_scroll",
          "params": {
            "max_scrolls": 5,
            "delay_between_scrolls": 2.0
          },
          "description": "滚动加载更多帖子"
        },
        {
          "action": "xiaohongshu_click_post",
          "params": {
            "title": "{{标题1}}"
          },
          "description": "点击指定帖子进入详情页"
        },
        {
          "action": "xiaohongshu_expand_comments",
          "params": {
            "max_attempts": 10
          },
          "description": "展开所有评论"
        },
        {
          "action": "xiaohongshu_extract_comments",
          "params": {
            "include_replies": true,
            "save_to_database": true
          },
          "description": "提取帖子内容和评论数据并存储到数据库"
        }
      ]
    }
  ],
  "persistent_id": "{{#conversation.sandbox_persistent_id#}}",
  "auto_cleanup": false,
  "total_posts": {{总数量}},
  "processing_mode": "batch_sequential"
}

## 处理要求
1. 为titles_array中的每个帖子都生成完整的操作序列
2. 保持标题的完整性，包括特殊字符和emoji
3. 按sequence顺序执行，确保不冲突
4. 严格按JSON格式输出
```

## 3. 节点连接顺序

```
SQL执行节点 → 数据转换节点 → 批量处理LLM节点 → 浏览器自动化节点 → 痛点分析节点
```

## 4. 变量引用示例

在后续节点中引用数据转换节点的输出：
- 标题数组：`{{#[数据转换节点ID].titles_array#}}`  
- 总数量：`{{#[数据转换节点ID].total_count#}}`
- 处理状态：`{{#[数据转换节点ID].status#}}`

## 5. 测试验证

配置完成后，用以下输入测试：
```
批量分析穿内衣聚拢方法倾囊相授，我们是真的听劝！！大胸显小内衣［细肩带］上啦，的帖子
```

应该能够：
1. ✅ SQL查询返回2条数据
2. ✅ 数据转换节点生成titles_array
3. ✅ 后续节点按序处理每个标题
4. ✅ 完成批量痛点分析
