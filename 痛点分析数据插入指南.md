# 小红书痛点分析数据插入指南

## 📋 **数据插入流程**

### **步骤1：解析JSON输出**

基于例子.md的输出格式，数据分为两个主要部分：
- `pain_point_analysis[]` - 具体内容分析数据
- `summary_insights{}` - 汇总洞察数据

### **步骤2：按表依赖顺序插入数据**

```
插入顺序：
1. xiaohongshu_pain_analysis (主表)
2. 详情表组 (并行插入)
   ├── xiaohongshu_pain_points
   ├── xiaohongshu_solved_problems  
   ├── xiaohongshu_user_needs
   ├── xiaohongshu_usage_scenarios
   ├── xiaohongshu_brand_mentions
   ├── xiaohongshu_product_models
   ├── xiaohongshu_emotional_keywords
   └── xiaohongshu_post_tags (仅帖子)
3. xiaohongshu_summary_insights (汇总主表)
4. 汇总详情表组 (并行插入)
   ├── xiaohongshu_high_frequency_pains
   ├── xiaohongshu_scenario_pain_ranking
   ├── xiaohongshu_brand_pain_correlation
   ├── xiaohongshu_urgent_needs
   └── xiaohongshu_market_opportunities
```

## 🔨 **具体插入SQL示例**

### **第一阶段：主表数据插入**

```sql
-- 1. 插入痛点分析主表
-- 基于 pain_point_analysis[0] 的数据
INSERT INTO xiaohongshu_pain_analysis (
    content_id, content_type, user_name, content_snippet,
    overall_sentiment, intensity_score, user_satisfaction,
    purchase_intent, recommendation_likelihood, competitor_comparison, price_sensitivity,
    analysis_batch
) VALUES (
    '68be9be5000000001b01dc71',  -- content_id
    'post',                       -- content_type  
    '小红薯68AFD76F',             -- user_name
    '想要你们的内裤推荐给我',      -- content_snippet
    '中性',                       -- overall_sentiment
    0.50,                         -- intensity_score
    '一般',                       -- user_satisfaction
    '高',                         -- purchase_intent
    '可能推荐',                   -- recommendation_likelihood
    '无',                         -- competitor_comparison (是否存在竞品对比转换)
    '中等',                       -- price_sensitivity
    'batch_20241221_001'          -- analysis_batch (分析批次)
);
```

### **第二阶段：详情表数据插入**

#### **A. 痛点详情表**
```sql
-- 基于 identified_pain_points[] 数组
INSERT INTO xiaohongshu_pain_points (content_id, pain_point, category, severity, evidence)
VALUES 
('68be9be5000000001b01dc71', '缺乏满意的内裤推荐', '舒适度', '中等', '想要你们的内裤推荐给我');
```

#### **B. 用户需求表**
```sql
-- 基于 user_needs[] 数组  
INSERT INTO xiaohongshu_user_needs (content_id, need, priority, need_type)
VALUES 
('68be9be5000000001b01dc71', '寻找舒适的内裤', '高', '功能性');
```

#### **C. 使用场景表**
```sql
-- 基于 usage_scenarios[] 数组
INSERT INTO xiaohongshu_usage_scenarios (content_id, scenario, frequency, pain_intensity)
VALUES 
('68be9be5000000001b01dc71', '日常通勤', '高频', '中');
```

#### **D. 情感关键词表**
```sql
-- 基于 emotional_analysis.emotional_keywords[] 数组
INSERT INTO xiaohongshu_emotional_keywords (content_id, keyword, keyword_order)
VALUES 
('68be9be5000000001b01dc71', '推荐', 1);
```

#### **E. 品牌提及表**
```sql
-- 基于 brand_mentions[] 数组 (该例子为空数组，跳过)
-- 如果有数据，如：["浙锦"]
INSERT INTO xiaohongshu_brand_mentions (content_id, brand_name, mention_order)
VALUES 
('68c3a47f000000001d00d976', '浙锦', 1);
```

#### **F. 产品型号表**  
```sql
-- 基于 product_models[] 数组
-- 例子：68bea6ac0000000030025e1a 的数据
INSERT INTO xiaohongshu_product_models (content_id, product_model, mention_order)
VALUES 
('68bea6ac0000000030025e1a', '莫代尔全棉加长底档中高腰', 1);
```

#### **G. 解决方案表**
```sql
-- 基于 solved_problems[] 数组
-- 例子：68becdba00000000300244cc 的数据
INSERT INTO xiaohongshu_solved_problems (content_id, problem, solution, satisfaction)
VALUES 
('68becdba00000000300244cc', '内裤卡裆问题', '选择不卡裆的内裤', '非常满意');
```

#### **H. 帖子标签表 (仅帖子类型)**
```sql
-- 基于 tags[] 数组 (注意：例子中没有tags，但提示词中有)
-- 假设帖子有标签：["内衣推荐", "无钢圈", "舒适"]
INSERT INTO xiaohongshu_post_tags (content_id, tag_name, tag_order)
VALUES 
('68be9be5000000001b01dc71', '内衣推荐', 1),
('68be9be5000000001b01dc71', '无钢圈', 2),
('68be9be5000000001b01dc71', '舒适', 3);
```

### **第三阶段：汇总数据插入**

#### **A. 汇总洞察主表**
```sql
-- 基于 summary_insights 对象
INSERT INTO xiaohongshu_summary_insights (
    analysis_batch, total_contents_analyzed, posts_count, comments_count,
    positive_sentiment_count, negative_sentiment_count, neutral_sentiment_count
) VALUES (
    'batch_20241221_001',  -- analysis_batch
    10,                    -- total_contents_analyzed (pain_point_analysis数组长度)
    1,                     -- posts_count (content_type='post'的数量)
    9,                     -- comments_count (content_type='comment'的数量)
    4,                     -- positive_sentiment_count  
    0,                     -- negative_sentiment_count
    6                      -- neutral_sentiment_count
);
```

#### **B. 高频痛点表**
```sql
-- 基于 high_frequency_pain_points[] 数组
INSERT INTO xiaohongshu_high_frequency_pains (analysis_batch, pain_point, frequency_rank, occurrence_count)
VALUES 
('batch_20241221_001', '尺码偏小', 1, 1),
('batch_20241221_001', '线头多', 2, 1),
('batch_20241221_001', '缺乏运费险', 3, 1);
```

#### **C. 场景痛点排名表**
```sql
-- 基于 scenario_pain_ranking 对象
INSERT INTO xiaohongshu_scenario_pain_ranking (analysis_batch, scenario_name, pain_point, ranking)
VALUES 
('batch_20241221_001', '日常通勤', '尺码偏小', 1),
('batch_20241221_001', '日常通勤', '线头多', 2),
('batch_20241221_001', '日常通勤', '缺乏运费险', 3);
```

#### **D. 紧急需求表**
```sql
-- 基于 urgent_needs[] 数组
INSERT INTO xiaohongshu_urgent_needs (analysis_batch, need_description, urgency_level, priority_rank)
VALUES 
('batch_20241221_001', '高舒适度内裤', '高', 1),
('batch_20241221_001', '不卡裆的内裤', '高', 2);
```

#### **E. 市场机会表**
```sql
-- 基于 market_opportunities[] 数组
INSERT INTO xiaohongshu_market_opportunities (analysis_batch, opportunity_description, opportunity_type, potential_impact, priority_rank)
VALUES 
('batch_20241221_001', '提供更多尺码选择', '产品创新', '高', 1),
('batch_20241221_001', '改进内裤设计减少线头', '产品创新', '中', 2),
('batch_20241221_001', '增加运费险服务', '服务优化', '中', 3);
```

## 🔄 **批量插入处理逻辑**

### **Python示例代码**

```python
import json
import pymysql
from datetime import datetime

def insert_pain_analysis_data(json_data, analysis_batch):
    """插入痛点分析数据到数据库"""
    
    # 1. 插入主表数据
    for item in json_data['pain_point_analysis']:
        insert_main_analysis(item, analysis_batch)
        
        # 2. 插入详情表数据
        insert_detail_tables(item)
    
    # 3. 插入汇总数据
    insert_summary_data(json_data['summary_insights'], analysis_batch)

def insert_main_analysis(item, batch):
    """插入主分析表"""
    sql = """
    INSERT INTO xiaohongshu_pain_analysis 
    (content_id, content_type, user_name, content_snippet, 
     overall_sentiment, intensity_score, user_satisfaction,
     purchase_intent, recommendation_likelihood, competitor_comparison, 
     price_sensitivity, analysis_batch)
    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
    """
    
    # 处理competitor_comparison字段转换
    competitor_comparison = '有' if item['commercial_insights']['competitor_comparison'] == '是' else '无'
    
    params = (
        item['content_id'],
        item['content_type'], 
        item['user_name'],
        item['content_snippet'],
        item['emotional_analysis']['overall_sentiment'],
        item['emotional_analysis']['intensity_score'],
        item['emotional_analysis']['user_satisfaction'],
        item['commercial_insights']['purchase_intent'],
        item['commercial_insights']['recommendation_likelihood'],
        competitor_comparison,
        item['commercial_insights']['price_sensitivity'],
        batch
    )
    
    execute_sql(sql, params)

def insert_detail_tables(item):
    """插入详情表数据"""
    content_id = item['content_id']
    
    # 痛点详情
    for pain in item['identified_pain_points']:
        sql = "INSERT INTO xiaohongshu_pain_points (content_id, pain_point, category, severity, evidence) VALUES (%s, %s, %s, %s, %s)"
        execute_sql(sql, (content_id, pain['pain_point'], pain['category'], pain['severity'], pain['evidence']))
    
    # 用户需求
    for need in item['user_needs']:
        sql = "INSERT INTO xiaohongshu_user_needs (content_id, need, priority, need_type) VALUES (%s, %s, %s, %s)"
        execute_sql(sql, (content_id, need['need'], need['priority'], need['type']))
    
    # 使用场景
    for scenario in item['usage_scenarios']:
        sql = "INSERT INTO xiaohongshu_usage_scenarios (content_id, scenario, frequency, pain_intensity) VALUES (%s, %s, %s, %s)"
        execute_sql(sql, (content_id, scenario['scenario'], scenario['frequency'], scenario['pain_intensity']))
    
    # 情感关键词
    for i, keyword in enumerate(item['emotional_analysis']['emotional_keywords'], 1):
        sql = "INSERT INTO xiaohongshu_emotional_keywords (content_id, keyword, keyword_order) VALUES (%s, %s, %s)"
        execute_sql(sql, (content_id, keyword, i))
    
    # 品牌提及
    for i, brand in enumerate(item['brand_mentions'], 1):
        sql = "INSERT INTO xiaohongshu_brand_mentions (content_id, brand_name, mention_order) VALUES (%s, %s, %s)"
        execute_sql(sql, (content_id, brand, i))
    
    # 产品型号
    for i, model in enumerate(item['product_models'], 1):
        sql = "INSERT INTO xiaohongshu_product_models (content_id, product_model, mention_order) VALUES (%s, %s, %s)"
        execute_sql(sql, (content_id, model, i))
    
    # 解决方案
    for solution in item['solved_problems']:
        sql = "INSERT INTO xiaohongshu_solved_problems (content_id, problem, solution, satisfaction) VALUES (%s, %s, %s, %s)"
        execute_sql(sql, (content_id, solution['problem'], solution['solution'], solution['satisfaction']))
    
    # 帖子标签 (仅帖子类型)
    if item['content_type'] == 'post' and 'tags' in item:
        for i, tag in enumerate(item['tags'], 1):
            sql = "INSERT INTO xiaohongshu_post_tags (content_id, tag_name, tag_order) VALUES (%s, %s, %s)"
            execute_sql(sql, (content_id, tag, i))

def insert_summary_data(summary, batch):
    """插入汇总数据"""
    # 插入汇总主表
    sql = """
    INSERT INTO xiaohongshu_summary_insights 
    (analysis_batch, total_contents_analyzed, posts_count, comments_count)
    VALUES (%s, %s, %s, %s)
    """
    # 这里需要根据实际统计计算counts
    execute_sql(sql, (batch, 10, 1, 9))  # 示例数据
    
    # 插入高频痛点
    for i, pain in enumerate(summary['high_frequency_pain_points'], 1):
        sql = "INSERT INTO xiaohongshu_high_frequency_pains (analysis_batch, pain_point, frequency_rank, occurrence_count) VALUES (%s, %s, %s, %s)"
        execute_sql(sql, (batch, pain, i, 1))  # occurrence_count需要实际统计
    
    # 插入紧急需求
    for i, need in enumerate(summary['urgent_needs'], 1):
        sql = "INSERT INTO xiaohongshu_urgent_needs (analysis_batch, need_description, urgency_level, priority_rank) VALUES (%s, %s, %s, %s)"
        execute_sql(sql, (batch, need, '高', i))
    
    # 插入市场机会
    for i, opportunity in enumerate(summary['market_opportunities'], 1):
        sql = "INSERT INTO xiaohongshu_market_opportunities (analysis_batch, opportunity_description, opportunity_type, potential_impact, priority_rank) VALUES (%s, %s, %s, %s, %s)"
        execute_sql(sql, (batch, opportunity, '产品创新', '高', i))

# 使用示例
if __name__ == "__main__":
    # 从例子.md读取JSON数据
    with open('例子.md', 'r', encoding='utf-8') as f:
        content = f.read()
    
    # 解析JSON（需要提取JSON部分）
    json_data = json.loads(json_content)
    
    # 生成分析批次
    batch_id = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    # 执行插入
    insert_pain_analysis_data(json_data, batch_id)
```

## ⚠️ **注意事项**

1. **数据完整性**：确保content_id在主表中存在后再插入详情表
2. **事务处理**：建议将一个JSON的所有插入操作包装在一个事务中
3. **批次管理**：使用analysis_batch字段关联同一批次的分析数据
4. **标签处理**：帖子标签表只处理content_type='post'的记录
5. **数据转换**：注意JSON中的字段值与数据库枚举值的映射关系
6. **错误处理**：添加重复插入检测和错误回滚机制

## 🎯 **插入后验证**

```sql
-- 验证数据插入完整性
SELECT 
    COUNT(*) as total_analysis,
    COUNT(CASE WHEN content_type = 'post' THEN 1 END) as posts,
    COUNT(CASE WHEN content_type = 'comment' THEN 1 END) as comments
FROM xiaohongshu_pain_analysis 
WHERE analysis_batch = 'batch_20241221_001';

-- 验证详情表数据
SELECT 'pain_points' as table_name, COUNT(*) as count FROM xiaohongshu_pain_points WHERE content_id IN (SELECT content_id FROM xiaohongshu_pain_analysis WHERE analysis_batch = 'batch_20241221_001')
UNION ALL
SELECT 'user_needs', COUNT(*) FROM xiaohongshu_user_needs WHERE content_id IN (SELECT content_id FROM xiaohongshu_pain_analysis WHERE analysis_batch = 'batch_20241221_001')
UNION ALL  
SELECT 'scenarios', COUNT(*) FROM xiaohongshu_usage_scenarios WHERE content_id IN (SELECT content_id FROM xiaohongshu_pain_analysis WHERE analysis_batch = 'batch_20241221_001');
```

按照这个流程，您就可以将例子.md中的JSON输出完整地插入到MySQL数据库中！
