"""
ç—›ç‚¹åˆ†æ API è·¯ç”±
æä¾›ç—›ç‚¹åˆ†ææ•°æ®çš„å­˜å‚¨å’ŒæŸ¥è¯¢æ¥å£
"""
from fastapi import APIRouter, HTTPException, Query
from typing import Optional, List, Dict, Any
import logging
import time
from datetime import datetime
from pydantic import ValidationError

from models.pain_analysis_models import (
    PainAnalysisRequest, PainAnalysisResponse, PainAnalysisStats,
    QueryPainAnalysisRequest, ContentType, Sentiment, PainCategory, Severity
)
from models.request_models import BaseResponse
from xiaohongshuDataStorage.pain_analysis_repository import pain_analysis_repository

logger = logging.getLogger(__name__)

# åˆ›å»ºè·¯ç”±å™¨
pain_analysis_router = APIRouter()

@pain_analysis_router.post("/store", response_model=PainAnalysisResponse)
async def store_pain_analysis_data(request: PainAnalysisRequest):
    """
    å­˜å‚¨ç—›ç‚¹åˆ†ææ•°æ®
    
    æ¥æ”¶ä¾‹å­.mdä¸­çš„JSONæ ¼å¼æ•°æ®ï¼Œå­˜å‚¨åˆ°ç›¸åº”çš„æ•°æ®åº“è¡¨ä¸­
    """
    start_time = time.time()
    
    try:
        logger.info(f"ğŸ“¥ æ¥æ”¶ç—›ç‚¹åˆ†ææ•°æ®å­˜å‚¨è¯·æ±‚: {len(request.pain_point_analysis)} æ¡è®°å½•")
        
        # è½¬æ¢Pydanticæ¨¡å‹ä¸ºå­—å…¸æ ¼å¼
        analysis_data = []
        for content in request.pain_point_analysis:
            # å°†Pydanticæ¨¡å‹è½¬æ¢ä¸ºå­—å…¸
            content_dict = content.dict()
            
            # å¤„ç†åµŒå¥—å­—æ®µçš„è½¬æ¢
            if content.user_needs:
                content_dict['user_needs'] = [need.dict() for need in content.user_needs]
            if content.identified_pain_points:
                content_dict['identified_pain_points'] = [pp.dict() for pp in content.identified_pain_points]
            if content.solved_problems:
                content_dict['solved_problems'] = [sp.dict() for sp in content.solved_problems]
            if content.usage_scenarios:
                content_dict['usage_scenarios'] = [us.dict() for us in content.usage_scenarios]
            
            # æ·»åŠ æƒ…æ„Ÿåˆ†æå’Œå•†ä¸šæ´å¯Ÿ
            content_dict['emotional_analysis'] = content.emotional_analysis.dict()
            content_dict['commercial_insights'] = content.commercial_insights.dict()
            
            analysis_data.append(content_dict)
        
        # è°ƒç”¨ä»“åº“å±‚å­˜å‚¨æ•°æ®
        result = pain_analysis_repository.store_pain_analysis_data(
            analysis_data=analysis_data,
            analysis_batch=request.analysis_batch
        )
        
        execution_time = round(time.time() - start_time, 2)
        
        if result['success']:
            logger.info(f"âœ… ç—›ç‚¹åˆ†ææ•°æ®å­˜å‚¨æˆåŠŸ: {result['message']}")
            return PainAnalysisResponse(
                success=True,
                message=result['message'],
                data={
                    'total_records': len(analysis_data),
                    'execution_time': execution_time
                },
                analysis_batch=result['stats']['analysis_batch'],
                storage_stats=result['stats']
            )
        else:
            logger.error(f"âŒ ç—›ç‚¹åˆ†ææ•°æ®å­˜å‚¨å¤±è´¥: {result['message']}")
            return PainAnalysisResponse(
                success=False,
                message=result['message'],
                analysis_batch=request.analysis_batch,
                storage_stats=result.get('stats')
            )
    
    except ValidationError as e:
        logger.error(f"âŒ è¯·æ±‚æ•°æ®éªŒè¯å¤±è´¥: {e.errors()}", exc_info=True)
        raise HTTPException(
            status_code=422,
            detail={"message": "è¯·æ±‚æ•°æ®éªŒè¯å¤±è´¥", "errors": e.errors()}
        )
    except Exception as e:
        logger.error(f"âŒ å­˜å‚¨ç—›ç‚¹åˆ†ææ•°æ®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")

@pain_analysis_router.get("/stats", response_model=BaseResponse)
async def get_pain_analysis_stats(
    analysis_batch: Optional[str] = Query(None, description="åˆ†ææ‰¹æ¬¡æ ‡è¯†")
):
    """
    è·å–ç—›ç‚¹åˆ†æç»Ÿè®¡ä¿¡æ¯
    """
    try:
        logger.info(f"ğŸ“Š è·å–ç—›ç‚¹åˆ†æç»Ÿè®¡ä¿¡æ¯: æ‰¹æ¬¡ {analysis_batch or 'å…¨éƒ¨'}")
        
        stats = pain_analysis_repository.get_pain_analysis_stats(analysis_batch)
        
        if 'error' in stats:
            return BaseResponse(
                success=False,
                message=f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {stats['error']}",
                data=None
            )
        
        return BaseResponse(
            success=True,
            message="ç»Ÿè®¡ä¿¡æ¯è·å–æˆåŠŸ",
            data={
                'statistics': stats,
                'analysis_batch': analysis_batch,
                'generated_at': datetime.now().isoformat()
            }
        )
    
    except Exception as e:
        logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        return BaseResponse(
            success=False,
            message=f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}",
            data=None
        )

@pain_analysis_router.get("/query", response_model=BaseResponse)
async def query_pain_analysis_data(
    analysis_batch: Optional[str] = Query(None, description="åˆ†ææ‰¹æ¬¡æ ‡è¯†"),
    content_type: Optional[ContentType] = Query(None, description="å†…å®¹ç±»å‹ç­›é€‰"),
    sentiment: Optional[Sentiment] = Query(None, description="æƒ…æ„Ÿç±»å‹ç­›é€‰"),
    pain_category: Optional[PainCategory] = Query(None, description="ç—›ç‚¹åˆ†ç±»ç­›é€‰"),
    severity: Optional[Severity] = Query(None, description="ä¸¥é‡ç¨‹åº¦ç­›é€‰"),
    limit: int = Query(50, ge=1, le=1000, description="è¿”å›æ•°é‡é™åˆ¶"),
    offset: int = Query(0, ge=0, description="åç§»é‡")
):
    """
    æŸ¥è¯¢ç—›ç‚¹åˆ†ææ•°æ®
    
    æ”¯æŒå¤šç§ç­›é€‰æ¡ä»¶çš„ç—›ç‚¹åˆ†ææ•°æ®æŸ¥è¯¢
    """
    try:
        logger.info(f"ğŸ” æŸ¥è¯¢ç—›ç‚¹åˆ†ææ•°æ®: æ‰¹æ¬¡ {analysis_batch}, ç±»å‹ {content_type}, æƒ…æ„Ÿ {sentiment}")
        
        conditions = {
            'analysis_batch': analysis_batch,
            'content_type': content_type.value if content_type else None,
            'sentiment': sentiment.value if sentiment else None,
            'pain_category': pain_category.value if pain_category else None,
            'severity': severity.value if severity else None,
            'limit': limit,
            'offset': offset
        }
        
        # ç§»é™¤Noneå€¼
        conditions = {k: v for k, v in conditions.items() if v is not None}
        
        results = pain_analysis_repository.query_pain_analysis(conditions)
        
        return BaseResponse(
            success=True,
            message=f"æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› {len(results)} æ¡è®°å½•",
            data={
                'results': results,
                'query_conditions': conditions,
                'total_returned': len(results),
                'queried_at': datetime.now().isoformat()
            }
        )
    
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢ç—›ç‚¹åˆ†ææ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        return BaseResponse(
            success=False,
            message=f"æŸ¥è¯¢å¤±è´¥: {str(e)}",
            data=None
        )

@pain_analysis_router.get("/batches", response_model=BaseResponse)
async def get_analysis_batches():
    """
    è·å–æ‰€æœ‰åˆ†ææ‰¹æ¬¡åˆ—è¡¨
    """
    try:
        logger.info("ğŸ“‹ è·å–åˆ†ææ‰¹æ¬¡åˆ—è¡¨")
        
        sql = """
        SELECT 
            analysis_batch,
            COUNT(*) as total_contents,
            MIN(created_at) as first_created,
            MAX(created_at) as last_created,
            COUNT(CASE WHEN content_type = 'post' THEN 1 END) as posts_count,
            COUNT(CASE WHEN content_type = 'comment' THEN 1 END) as comments_count
        FROM xiaohongshu_pain_analysis 
        WHERE analysis_batch IS NOT NULL
        GROUP BY analysis_batch 
        ORDER BY last_created DESC
        """
        
        from xiaohongshuDataStorage.connect_manager import db_manager
        batches = db_manager.execute_query(sql)
        
        return BaseResponse(
            success=True,
            message=f"è·å–åˆ° {len(batches)} ä¸ªåˆ†ææ‰¹æ¬¡",
            data={
                'batches': batches,
                'total_batches': len(batches),
                'generated_at': datetime.now().isoformat()
            }
        )
    
    except Exception as e:
        logger.error(f"âŒ è·å–åˆ†ææ‰¹æ¬¡åˆ—è¡¨æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        return BaseResponse(
            success=False,
            message=f"è·å–æ‰¹æ¬¡åˆ—è¡¨å¤±è´¥: {str(e)}",
            data=None
        )

@pain_analysis_router.delete("/batch/{analysis_batch}", response_model=BaseResponse)
async def delete_analysis_batch(analysis_batch: str):
    """
    åˆ é™¤æŒ‡å®šæ‰¹æ¬¡çš„åˆ†ææ•°æ®
    """
    try:
        logger.info(f"ğŸ—‘ï¸ åˆ é™¤åˆ†ææ‰¹æ¬¡: {analysis_batch}")
        
        success = pain_analysis_repository.delete_analysis_batch(analysis_batch)
        
        if success:
            return BaseResponse(
                success=True,
                message=f"æˆåŠŸåˆ é™¤æ‰¹æ¬¡ {analysis_batch} çš„æ‰€æœ‰æ•°æ®",
                data={'deleted_batch': analysis_batch}
            )
        else:
            return BaseResponse(
                success=False,
                message=f"åˆ é™¤æ‰¹æ¬¡ {analysis_batch} å¤±è´¥ï¼Œæ‰¹æ¬¡å¯èƒ½ä¸å­˜åœ¨",
                data=None
            )
    
    except Exception as e:
        logger.error(f"âŒ åˆ é™¤åˆ†ææ‰¹æ¬¡æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        return BaseResponse(
            success=False,
            message=f"åˆ é™¤æ‰¹æ¬¡å¤±è´¥: {str(e)}",
            data=None
        )

@pain_analysis_router.get("/content/{content_id}", response_model=BaseResponse)
async def get_content_detail(content_id: str):
    """
    è·å–ç‰¹å®šå†…å®¹çš„è¯¦ç»†åˆ†ææ•°æ®
    """
    try:
        logger.info(f"ğŸ“„ è·å–å†…å®¹è¯¦æƒ…: {content_id}")
        
        from xiaohongshuDataStorage.connect_manager import db_manager
        
        # è·å–ä¸»è¦å†…å®¹ä¿¡æ¯
        main_sql = "SELECT * FROM xiaohongshu_pain_analysis WHERE content_id = %s"
        main_data = db_manager.execute_query(main_sql, (content_id,))
        
        if not main_data:
            raise HTTPException(status_code=404, detail=f"å†…å®¹ {content_id} ä¸å­˜åœ¨")
        
        content_detail = main_data[0]
        
        # è·å–ç›¸å…³çš„å­è¡¨æ•°æ®
        tables_data = {}
        
        # ç—›ç‚¹æ•°æ®
        pain_points = db_manager.execute_query(
            "SELECT * FROM xiaohongshu_pain_points WHERE content_id = %s ORDER BY id",
            (content_id,)
        )
        tables_data['pain_points'] = pain_points
        
        # è§£å†³æ–¹æ¡ˆæ•°æ®
        solved_problems = db_manager.execute_query(
            "SELECT * FROM xiaohongshu_solved_problems WHERE content_id = %s ORDER BY id",
            (content_id,)
        )
        tables_data['solved_problems'] = solved_problems
        
        # ç”¨æˆ·éœ€æ±‚æ•°æ®
        user_needs = db_manager.execute_query(
            "SELECT * FROM xiaohongshu_user_needs WHERE content_id = %s ORDER BY id",
            (content_id,)
        )
        tables_data['user_needs'] = user_needs
        
        # ä½¿ç”¨åœºæ™¯æ•°æ®
        usage_scenarios = db_manager.execute_query(
            "SELECT * FROM xiaohongshu_usage_scenarios WHERE content_id = %s ORDER BY id",
            (content_id,)
        )
        tables_data['usage_scenarios'] = usage_scenarios
        
        # å“ç‰ŒæåŠæ•°æ®
        brand_mentions = db_manager.execute_query(
            "SELECT * FROM xiaohongshu_brand_mentions WHERE content_id = %s ORDER BY mention_order",
            (content_id,)
        )
        tables_data['brand_mentions'] = brand_mentions
        
        # äº§å“å‹å·æ•°æ®
        product_models = db_manager.execute_query(
            "SELECT * FROM xiaohongshu_product_models WHERE content_id = %s ORDER BY mention_order",
            (content_id,)
        )
        tables_data['product_models'] = product_models
        
        # æƒ…æ„Ÿå…³é”®è¯æ•°æ®
        emotional_keywords = db_manager.execute_query(
            "SELECT * FROM xiaohongshu_emotional_keywords WHERE content_id = %s ORDER BY keyword_order",
            (content_id,)
        )
        tables_data['emotional_keywords'] = emotional_keywords
        
        # å¸–å­æ ‡ç­¾æ•°æ®ï¼ˆå¦‚æœæ˜¯å¸–å­ï¼‰
        if content_detail['content_type'] == 'post':
            post_tags = db_manager.execute_query(
                "SELECT * FROM xiaohongshu_post_tags WHERE content_id = %s ORDER BY tag_order",
                (content_id,)
            )
            tables_data['post_tags'] = post_tags
        
        return BaseResponse(
            success=True,
            message=f"æˆåŠŸè·å–å†…å®¹ {content_id} çš„è¯¦ç»†ä¿¡æ¯",
            data={
                'main_data': content_detail,
                'related_data': tables_data,
                'content_id': content_id,
                'queried_at': datetime.now().isoformat()
            }
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–å†…å®¹è¯¦æƒ…æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        return BaseResponse(
            success=False,
            message=f"è·å–å†…å®¹è¯¦æƒ…å¤±è´¥: {str(e)}",
            data=None
        )

@pain_analysis_router.get("/health", response_model=BaseResponse)
async def health_check():
    """
    ç—›ç‚¹åˆ†ææ¨¡å—å¥åº·æ£€æŸ¥
    """
    try:
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        from xiaohongshuDataStorage.connect_manager import db_manager
        health = db_manager.health_check()
        
        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        tables_status = {}
        required_tables = [
            'xiaohongshu_pain_analysis',
            'xiaohongshu_pain_points', 
            'xiaohongshu_solved_problems',
            'xiaohongshu_user_needs',
            'xiaohongshu_usage_scenarios',
            'xiaohongshu_brand_mentions',
            'xiaohongshu_product_models',
            'xiaohongshu_emotional_keywords',
            'xiaohongshu_post_tags'
        ]
        
        for table in required_tables:
            try:
                result = db_manager.execute_query(f"SELECT COUNT(*) as count FROM {table} LIMIT 1")
                tables_status[table] = {'exists': True, 'count': result[0]['count']}
            except Exception as e:
                tables_status[table] = {'exists': False, 'error': str(e)}
        
        all_tables_exist = all(status['exists'] for status in tables_status.values())
        
        return BaseResponse(
            success=health['status'] == 'healthy' and all_tables_exist,
            message="ç—›ç‚¹åˆ†ææ¨¡å—å¥åº·æ£€æŸ¥å®Œæˆ",
            data={
                'database_health': health,
                'tables_status': tables_status,
                'all_tables_exist': all_tables_exist,
                'checked_at': datetime.now().isoformat()
            }
        )
    
    except Exception as e:
        logger.error(f"âŒ å¥åº·æ£€æŸ¥æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        return BaseResponse(
            success=False,
            message=f"å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}",
            data=None
        )
