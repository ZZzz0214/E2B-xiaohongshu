"""
å°çº¢ä¹¦ç»Ÿä¸€å†…å®¹è¡¨æ“ä½œ
å¤„ç†å¸–å­è¯¦æƒ…ã€ä¸»è¯„è®ºã€å›å¤è¯„è®ºçš„ç»Ÿä¸€å­˜å‚¨
"""
import logging
import hashlib
from typing import Dict, Any, List, Optional, Union
from datetime import datetime, timezone
import json
import pymysql

from .connect_manager import db_manager

logger = logging.getLogger(__name__)

class ContentUnifiedRepository:
    """ç»Ÿä¸€å†…å®¹è¡¨æ•°æ®æ“ä½œç±»"""
    
    def __init__(self):
        self.db_manager = db_manager
    
    def _generate_content_hash(self, content: str) -> str:
        """ç”Ÿæˆå†…å®¹å“ˆå¸Œå€¼ï¼Œç”¨äºå»é‡"""
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def _parse_timestamp(self, time_str: str) -> Optional[datetime]:
        """è§£ææ—¶é—´å­—ç¬¦ä¸²ä¸ºdatetimeå¯¹è±¡"""
        if not time_str:
            return None
            
        # å¤„ç†å„ç§æ—¶é—´æ ¼å¼
        formats = [
            "%Y/%m/%d %H:%M:%S",  # 2025/9/5 23:18:18
            "%Y-%m-%d %H:%M:%S",  # 2025-09-05 23:18:18
            "%Y/%m/%d",           # 2025/9/5
            "%Y-%m-%d"            # 2025-09-05
        ]
        
        for fmt in formats:
            try:
                return datetime.strptime(time_str, fmt)
            except ValueError:
                continue
        
        # å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œè®°å½•è­¦å‘Šå¹¶è¿”å›None
        logger.warning(f"æ— æ³•è§£ææ—¶é—´æ ¼å¼: {time_str}")
        return None
    
    def store_post_content(self, post_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        å­˜å‚¨å¸–å­æ­£æ–‡å†…å®¹
        
        Args:
            post_data: å¸–å­è¯¦æƒ…æ•°æ®
            
        Returns:
            å­˜å‚¨ç»“æœ
        """
        try:
            # æå–å¸–å­ä¿¡æ¯
            post_id = post_data.get('post_id')
            title = post_data.get('title', '')
            description = post_data.get('description', '')
            
            # ç”¨æˆ·ä¿¡æ¯
            author = post_data.get('author', {})
            user_id = author.get('user_id') or post_data.get('author_id')
            user_name = author.get('nickname') or post_data.get('author_name', '')
            user_avatar = author.get('avatar', '')
            
            # æ—¶é—´ä¿¡æ¯
            publish_time = post_data.get('publish_time')
            content_time = None
            publish_date = None
            
            if publish_time:
                try:
                    # å‡è®¾æ˜¯æ¯«ç§’æ—¶é—´æˆ³
                    content_time = datetime.fromtimestamp(publish_time / 1000)
                    publish_date = content_time.date()
                except (ValueError, TypeError):
                    logger.warning(f"æ— æ³•è§£æå‘å¸ƒæ—¶é—´: {publish_time}")
            
            # æ„å»ºå¯Œå†…å®¹JSON
            rich_content = {}
            if 'tags' in post_data:
                rich_content['tags'] = post_data['tags']
            
            # äº’åŠ¨æ•°æ®
            interaction_stats = {}
            if 'like_count' in post_data or 'collect_count' in post_data:
                interaction_stats = {
                    'likes': post_data.get('like_count', 0),
                    'collects': post_data.get('collect_count', 0),
                    'comments': post_data.get('comment_count', 0),
                    'shares': post_data.get('share_count', 0)
                }
            
            # æ„å»ºæ’å…¥æ•°æ®
            insert_data = {
                'post_id': post_id,
                'content_id': post_id,  # å¸–å­çš„content_idå°±æ˜¯post_id
                'parent_id': None,
                'content_level': 0,
                'display_order': 0,
                'thread_group': None,
                'content_type': 'post',
                'title': title,
                'content': description,
                'rich_content': json.dumps(rich_content, ensure_ascii=False) if rich_content else None,
                'user_id': user_id,
                'user_name': user_name,
                'user_avatar': user_avatar,
                'is_post_author': True,
                'interaction_stats': json.dumps(interaction_stats, ensure_ascii=False) if interaction_stats else None,
                'content_timestamp': publish_time,
                'content_time': content_time,
                'publish_date': publish_date,
                'ip_location': None,
                'content_hash': self._generate_content_hash(description),
                'extraction_source': 'global_state'
            }
            
            # æ‰§è¡Œæ’å…¥/æ›´æ–°
            result = self._upsert_content(insert_data)
            
            logger.info(f"âœ… å¸–å­å†…å®¹å­˜å‚¨æˆåŠŸ: {post_id}")
            return {
                'success': True,
                'content_id': post_id,
                'content_type': 'post',
                'operation': result['operation']
            }
            
        except Exception as e:
            logger.error(f"âŒ å¸–å­å†…å®¹å­˜å‚¨å¤±è´¥: {e}", exc_info=True)
            return {
                'success': False,
                'error': str(e),
                'content_id': post_data.get('post_id'),
                'content_type': 'post'
            }
    
    def store_comments(self, post_id: str, comments_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        å­˜å‚¨è¯„è®ºæ•°æ®
        
        Args:
            post_id: å¸–å­ID
            comments_data: è¯„è®ºåˆ—è¡¨
            
        Returns:
            å­˜å‚¨ç»“æœç»Ÿè®¡
        """
        if not comments_data:
            return {
                'success': True,
                'stats': {'total': 0, 'success': 0, 'error': 0},
                'details': []
            }
        
        logger.info(f"ğŸ’¬ å¼€å§‹å­˜å‚¨ {len(comments_data)} æ¡è¯„è®º...")
        
        results = []
        success_count = 0
        error_count = 0
        
        for comment in comments_data:
            try:
                # æå–è¯„è®ºä¿¡æ¯
                comment_id = comment.get('id')
                content = comment.get('content', '')
                raw_comment_type = comment.get('type', 'main')  # main æˆ– reply
                # æ˜ å°„åˆ°æ•°æ®åº“ENUMå€¼
                comment_type = 'reply' if raw_comment_type == 'reply' else 'comment'
                parent_comment_id = comment.get('parent_comment_id')
                
                # ç”¨æˆ·ä¿¡æ¯
                user_id = comment.get('user_id')
                user_name = comment.get('user', '')
                is_author = comment.get('is_author', False)
                
                # æ—¶é—´å’Œä½ç½®
                time_str = comment.get('time', '')
                content_time = self._parse_timestamp(time_str)
                publish_date = content_time.date() if content_time else None
                ip_location = comment.get('location')
                
                # å±‚çº§ä¿¡æ¯
                content_level = 2 if comment_type == 'reply' else 1
                display_order = comment.get('index', 0)
                thread_group = None
                
                # å¦‚æœæ˜¯å›å¤ï¼Œæ‰¾åˆ°æ‰€å±çš„ä¸»è¯„è®ºç»„
                if comment_type == 'reply' and parent_comment_id:
                    thread_group = self._get_main_comment_thread_group(parent_comment_id)
                else:
                    # ä¸»è¯„è®ºçš„thread_groupå°±æ˜¯å…¶display_order
                    thread_group = display_order
                
                # äº’åŠ¨æ•°æ®
                interaction_stats = {
                    'likes': int(comment.get('like_count', 0)) if comment.get('like_count', '0').isdigit() else 0,
                    'replies': int(comment.get('reply_count', 0)) if isinstance(comment.get('reply_count'), (int, str)) else 0
                }
                
                # æ„å»ºæ’å…¥æ•°æ®
                insert_data = {
                    'post_id': post_id,
                    'content_id': comment_id,
                    'parent_id': parent_comment_id,
                    'content_level': content_level,
                    'display_order': display_order,
                    'thread_group': thread_group,
                    'content_type': comment_type,
                    'title': None,
                    'content': content,
                    'rich_content': None,
                    'user_id': user_id,
                    'user_name': user_name,
                    'user_avatar': None,
                    'is_post_author': is_author,
                    'interaction_stats': json.dumps(interaction_stats, ensure_ascii=False),
                    'content_timestamp': None,
                    'content_time': content_time,
                    'publish_date': publish_date,
                    'ip_location': ip_location,
                    'content_hash': self._generate_content_hash(content),
                    'extraction_source': 'global_state'
                }
                
                # æ‰§è¡Œæ’å…¥/æ›´æ–°
                result = self._upsert_content(insert_data)
                
                results.append({
                    'success': True,
                    'content_id': comment_id,
                    'content_type': comment_type,
                    'operation': result['operation']
                })
                success_count += 1
                
                logger.debug(f"âœ… è¯„è®ºå­˜å‚¨æˆåŠŸ: {comment_id}")
                
            except Exception as e:
                logger.error(f"âŒ è¯„è®ºå­˜å‚¨å¤±è´¥ {comment.get('id')}: {e}")
                results.append({
                    'success': False,
                    'error': str(e),
                    'content_id': comment.get('id'),
                    'content_type': comment_type if 'comment_type' in locals() else 'comment'
                })
                error_count += 1
        
        logger.info(f"ğŸ’¬ è¯„è®ºå­˜å‚¨å®Œæˆ: {success_count} æˆåŠŸ, {error_count} å¤±è´¥")
        
        return {
            'success': error_count == 0,
            'stats': {
                'total': len(comments_data),
                'success': success_count,
                'error': error_count
            },
            'details': results
        }
    
    def _get_main_comment_thread_group(self, parent_comment_id: str) -> Optional[int]:
        """è·å–ä¸»è¯„è®ºçš„thread_group"""
        try:
            with self.db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute(
                        """
                        SELECT thread_group FROM xiaohongshu_content_unified 
                        WHERE content_id = %s AND content_level = 1
                        """,
                        (parent_comment_id,)
                    )
                    result = cursor.fetchone()
                    return result['thread_group'] if result else None
        except Exception as e:
            logger.error(f"æŸ¥è¯¢ä¸»è¯„è®ºthread_groupå¤±è´¥: {e}")
            return None
    
    def _upsert_content(self, data: Dict[str, Any]) -> Dict[str, str]:
        """
        æ’å…¥æˆ–æ›´æ–°å†…å®¹è®°å½•
        
        Args:
            data: å†…å®¹æ•°æ®
            
        Returns:
            æ“ä½œç»“æœ
        """
        try:
            with self.db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    # æ„å»ºæ’å…¥SQL
                    columns = list(data.keys())
                    placeholders = ', '.join(['%s'] * len(columns))
                    column_names = ', '.join(columns)
                    
                    # æ„å»ºON DUPLICATE KEY UPDATEå­å¥
                    update_clauses = []
                    for col in columns:
                        if col not in ['id', 'content_id', 'crawl_time']:  # æ’é™¤ä¸»é”®å’Œå”¯ä¸€é”®
                            update_clauses.append(f"{col} = VALUES({col})")
                    
                    sql = f"""
                        INSERT INTO xiaohongshu_content_unified ({column_names})
                        VALUES ({placeholders})
                        ON DUPLICATE KEY UPDATE
                        {', '.join(update_clauses)},
                        updated_at = CURRENT_TIMESTAMP
                    """
                    
                    values = list(data.values())
                    cursor.execute(sql, values)
                    
                    # åˆ¤æ–­æ˜¯æ’å…¥è¿˜æ˜¯æ›´æ–°
                    if cursor.rowcount == 1:
                        operation = 'insert'
                    elif cursor.rowcount == 2:
                        operation = 'update'
                    else:
                        operation = 'no_change'
                    
                    conn.commit()
                    return {'operation': operation}
                    
        except Exception as e:
            logger.error(f"å†…å®¹upsertæ“ä½œå¤±è´¥: {e}")
            raise
    
    def get_content_stats(self, post_id: Optional[str] = None) -> Dict[str, Any]:
        """
        è·å–å†…å®¹ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            post_id: æŒ‡å®šå¸–å­IDï¼Œä¸ºNoneæ—¶è¿”å›å…¨å±€ç»Ÿè®¡
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            with self.db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    where_clause = "WHERE post_id = %s" if post_id else ""
                    params = [post_id] if post_id else []
                    
                    cursor.execute(f"""
                        SELECT 
                            content_type,
                            COUNT(*) as count,
                            COUNT(CASE WHEN is_deleted = 0 THEN 1 END) as active_count
                        FROM xiaohongshu_content_unified 
                        {where_clause}
                        GROUP BY content_type
                    """, params)
                    
                    results = cursor.fetchall()
                    stats = {}
                    
                    for row in results:
                        stats[row['content_type']] = {
                            'total': int(row['count']),
                            'active': int(row['active_count'])
                        }
                    
                    return {
                        'success': True,
                        'stats': stats,
                        'post_id': post_id
                    }
                    
        except Exception as e:
            logger.error(f"è·å–å†…å®¹ç»Ÿè®¡å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }

# åˆ›å»ºå…¨å±€å®ä¾‹
content_unified_repository = ContentUnifiedRepository() 