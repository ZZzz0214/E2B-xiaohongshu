"""
AIåˆ†ææ•°æ®ä»“åº“
è´Ÿè´£xiaohongshu_ai_analysisè¡¨çš„æ•°æ®åº“æ“ä½œ
"""
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

from .connect_manager import db_manager

logger = logging.getLogger(__name__)

class AIAnalysisRepository:
    """AIåˆ†ææ•°æ®ä»“åº“"""
    
    def __init__(self):
        self.table_name = "xiaohongshu_ai_analysis"
    
    def get_content_unified_id_by_comment_id(self, comment_id: str) -> Optional[int]:
        """
        æ ¹æ®comment_idæŸ¥æ‰¾å¯¹åº”çš„content_unified_id
        
        Args:
            comment_id: è¯„è®ºID
            
        Returns:
            content_unified_idæˆ–None
        """
        try:
            with db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    sql = """
                    SELECT id as content_unified_id 
                    FROM xiaohongshu_content_unified 
                    WHERE content_id = %s AND content_type IN ('comment', 'reply')
                    """
                    cursor.execute(sql, (comment_id,))
                    result = cursor.fetchone()
                    
                    if result:
                        return result['content_unified_id']
                    else:
                        logger.warning(f"æœªæ‰¾åˆ°comment_idå¯¹åº”çš„content_unified_id: {comment_id}")
                        return None
                        
        except Exception as e:
            logger.error(f"æŸ¥è¯¢content_unified_idå¤±è´¥: {comment_id} - {e}")
            return None
    
    def get_classification_id_by_post_id(self, post_id: str) -> Optional[int]:
        """
        æ ¹æ®post_idæŸ¥æ‰¾å¯¹åº”çš„classification_id
        
        Args:
            post_id: å¸–å­ID
            
        Returns:
            classification_idæˆ–None
        """
        try:
            with db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    sql = """
                    SELECT id as classification_id 
                    FROM xiaohongshu_content_classification 
                    WHERE post_id = %s
                    """
                    cursor.execute(sql, (post_id,))
                    result = cursor.fetchone()
                    
                    if result:
                        return result['classification_id']
                    else:
                        logger.warning(f"æœªæ‰¾åˆ°post_idå¯¹åº”çš„classification_id: {post_id}")
                        return None
                        
        except Exception as e:
            logger.error(f"æŸ¥è¯¢classification_idå¤±è´¥: {post_id} - {e}")
            return None
    
    def insert_comment_analysis(self, analysis_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ’å…¥è¯„è®ºåˆ†æç»“æœ
        
        Args:
            analysis_data: åˆ†ææ•°æ®å­—å…¸
            
        Returns:
            æ“ä½œç»“æœ
        """
        try:
            comment_id = analysis_data.get('comment_id')
            
            # è·å–content_unified_id
            content_unified_id = self.get_content_unified_id_by_comment_id(comment_id)
            if content_unified_id is None:
                return {
                    'success': False,
                    'error': f'æ‰¾ä¸åˆ°comment_idå¯¹åº”çš„åŸå§‹æ•°æ®: {comment_id}',
                    'comment_id': comment_id
                }
            
            # è·å–classification_idï¼ˆé€šè¿‡å¸–å­IDæ¨æ–­ï¼‰
            # ç”±äºæˆ‘ä»¬æ²¡æœ‰ç›´æ¥çš„post_idï¼Œæˆ‘ä»¬å…ˆæŸ¥æ‰¾è¿™ä¸ªè¯„è®ºæ‰€å±çš„å¸–å­
            post_id = self.get_post_id_by_comment_id(comment_id)
            if post_id is None:
                return {
                    'success': False,
                    'error': f'æ‰¾ä¸åˆ°comment_idå¯¹åº”çš„post_id: {comment_id}',
                    'comment_id': comment_id
                }
            
            classification_id = self.get_classification_id_by_post_id(post_id)
            if classification_id is None:
                return {
                    'success': False,
                    'error': f'æ‰¾ä¸åˆ°post_idå¯¹åº”çš„classification_id: {post_id}',
                    'comment_id': comment_id
                }
            
            # å‡†å¤‡æ’å…¥æ•°æ®
            sql = """
            INSERT INTO xiaohongshu_ai_analysis 
            (classification_id, content_unified_id, post_id, is_valid, confidence,
             product_category, functional_needs, user_profile, size_info, 
             user_pain_points, brands, intent_type, intent_level, business_value,
             follow_up_action, sentiment, analysis_batch, created_at)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE
                is_valid = VALUES(is_valid),
                confidence = VALUES(confidence),
                intent_type = VALUES(intent_type),
                intent_level = VALUES(intent_level),
                sentiment = VALUES(sentiment),
                business_value = VALUES(business_value),
                follow_up_action = VALUES(follow_up_action)
            """
            
            # ä»key_featuresä¸­æå–å­—æ®µ
            key_features = analysis_data.get('key_features', {})
            
            params = (
                classification_id,
                content_unified_id,
                post_id,
                analysis_data.get('is_valid', True),
                analysis_data.get('confidence', 0.8),
                key_features.get('product_category'),
                key_features.get('functional_needs'),
                key_features.get('user_profile'),
                key_features.get('size_info'),
                None,  # user_pain_points - æ•°æ®ä¸­æ²¡æœ‰
                None,  # brands - æ•°æ®ä¸­æ²¡æœ‰
                analysis_data.get('intent_type'),
                analysis_data.get('intent_level'),
                analysis_data.get('business_value'),
                analysis_data.get('follow_up_action'),
                analysis_data.get('sentiment'),
                f"batch_{int(datetime.now().timestamp())}",  # analysis_batch
                datetime.now()
            )
            
            with db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute(sql, params)
                    conn.commit()
                    
                    affected_rows = cursor.rowcount
                    
                    if affected_rows == 1:
                        logger.debug(f"âœ… è¯„è®ºåˆ†ææ’å…¥æˆåŠŸ: {comment_id}")
                        operation = "inserted"
                    elif affected_rows == 2:
                        logger.debug(f"ğŸ”„ è¯„è®ºåˆ†ææ›´æ–°æˆåŠŸ: {comment_id}")
                        operation = "updated"
                    else:
                        logger.debug(f"ğŸ“‹ è¯„è®ºåˆ†ææ— å˜åŒ–: {comment_id}")
                        operation = "no_change"
                    
                    return {
                        'success': True,
                        'comment_id': comment_id,
                        'content_unified_id': content_unified_id,
                        'classification_id': classification_id,
                        'operation': operation
                    }
                    
        except Exception as e:
            logger.error(f"âŒ è¯„è®ºåˆ†ææ’å…¥å¤±è´¥: {comment_id} - {e}")
            return {
                'success': False,
                'error': str(e),
                'comment_id': comment_id
            }
    
    def get_post_id_by_comment_id(self, comment_id: str) -> Optional[str]:
        """
        æ ¹æ®comment_idæŸ¥æ‰¾æ‰€å±çš„post_id
        
        Args:
            comment_id: è¯„è®ºID
            
        Returns:
            post_idæˆ–None
        """
        try:
            with db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    sql = """
                    SELECT post_id 
                    FROM xiaohongshu_content_unified 
                    WHERE content_id = %s AND content_type IN ('comment', 'reply')
                    """
                    cursor.execute(sql, (comment_id,))
                    result = cursor.fetchone()
                    
                    if result:
                        return result['post_id']
                    else:
                        return None
                        
        except Exception as e:
            logger.error(f"æŸ¥è¯¢post_idå¤±è´¥: {comment_id} - {e}")
            return None
    
    def batch_insert_comment_analysis(self, analyses: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        æ‰¹é‡æ’å…¥è¯„è®ºåˆ†æç»“æœ
        
        Args:
            analyses: åˆ†ææ•°æ®åˆ—è¡¨
            
        Returns:
            æ‰¹é‡æ“ä½œç»“æœ
        """
        start_time = datetime.now()
        
        stored_comments = []
        failed_comments = []
        
        logger.info(f"ğŸ“Š å¼€å§‹æ‰¹é‡æ’å…¥è¯„è®ºåˆ†æ: {len(analyses)} æ¡")
        
        for analysis in analyses:
            result = self.insert_comment_analysis(analysis)
            
            if result['success']:
                stored_comments.append({
                    'comment_id': result['comment_id'],
                    'content_unified_id': result['content_unified_id'],
                    'classification_id': result['classification_id'],
                    'operation': result['operation']
                })
            else:
                failed_comments.append({
                    'comment_id': result['comment_id'],
                    'error': result['error']
                })
        
        execution_time = (datetime.now() - start_time).total_seconds()
        
        result = {
            'success': len(stored_comments) > 0,
            'total_count': len(analyses),
            'stored_count': len(stored_comments),
            'failed_count': len(failed_comments),
            'stored_comments': stored_comments,
            'failed_comments': failed_comments,
            'execution_time': execution_time,
            'stored_at': datetime.now().isoformat()
        }
        
        logger.info(f"âœ… æ‰¹é‡æ’å…¥å®Œæˆ: {len(stored_comments)} æˆåŠŸ, {len(failed_comments)} å¤±è´¥, è€—æ—¶ {execution_time:.2f}s")
        
        return result

# åˆ›å»ºå…¨å±€å®ä¾‹
ai_analysis_repository = AIAnalysisRepository()
