"""
å¸–å­åˆ†ç±»æ•°æ®ä»“åº“
è´Ÿè´£xiaohongshu_content_classificationè¡¨çš„æ•°æ®åº“æ“ä½œ
"""
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

from .connect_manager import db_manager

logger = logging.getLogger(__name__)

class ClassificationRepository:
    """å¸–å­åˆ†ç±»æ•°æ®ä»“åº“"""
    
    def __init__(self):
        self.table_name = "xiaohongshu_content_classification"
    
    def get_post_info_by_post_id(self, post_id: str) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ®post_idä»xiaohongshu_postsè¡¨æŸ¥æ‰¾å¸–å­ä¿¡æ¯
        
        Args:
            post_id: å¸–å­ID
            
        Returns:
            å¸–å­ä¿¡æ¯å­—å…¸æˆ–None
        """
        try:
            with db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    sql = """
                    SELECT post_id, author_id, author_name, title 
                    FROM xiaohongshu_posts 
                    WHERE post_id = %s
                    """
                    cursor.execute(sql, (post_id,))
                    result = cursor.fetchone()
                    
                    if result:
                        return dict(result)
                    else:
                        logger.warning(f"æœªæ‰¾åˆ°post_idåœ¨xiaohongshu_postsè¡¨ä¸­: {post_id}")
                        return None
                        
        except Exception as e:
            logger.error(f"æŸ¥è¯¢å¸–å­ä¿¡æ¯å¤±è´¥: {post_id} - {e}")
            return None
    
    def insert_classification(self, classification_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ’å…¥å¸–å­åˆ†ç±»ç»“æœ
        
        Args:
            classification_data: åˆ†ç±»æ•°æ®å­—å…¸
            
        Returns:
            æ“ä½œç»“æœ
        """
        try:
            # é¦–å…ˆä»xiaohongshu_postsè¡¨è·å–å¸–å­ä¿¡æ¯
            post_id = classification_data.get('post_id')
            post_info = self.get_post_info_by_post_id(post_id)
            
            if post_info is None:
                return {
                    'success': False,
                    'error': f'æ‰¾ä¸åˆ°post_idåœ¨xiaohongshu_postsè¡¨ä¸­: {post_id}',
                    'post_id': post_id
                }
            
            # å‡†å¤‡æ’å…¥æ•°æ® - ä½¿ç”¨æ•°æ®åº“ä¸­çš„çœŸå®ä¿¡æ¯
            sql = """
            INSERT INTO xiaohongshu_content_classification 
            (content_unified_id, post_id, author_id, author_name, title, 
             classification, confidence_score, reasoning, commercial_value, 
             need_ai_analysis, analysis_model, analysis_version, created_at)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE
                classification = VALUES(classification),
                confidence_score = VALUES(confidence_score),
                reasoning = VALUES(reasoning),
                commercial_value = VALUES(commercial_value),
                need_ai_analysis = VALUES(need_ai_analysis),
                updated_at = CURRENT_TIMESTAMP
            """
            
            params = (
                None,  # content_unified_id è®¾ä¸º NULLï¼Œå¸–å­åˆ†ç±»ä¸éœ€è¦ä¾èµ– content_unified è¡¨
                post_info['post_id'],              # ä½¿ç”¨æ•°æ®åº“ä¸­çš„ post_id
                post_info['author_id'],            # ä½¿ç”¨æ•°æ®åº“ä¸­çš„ author_id
                post_info['author_name'],          # ä½¿ç”¨æ•°æ®åº“ä¸­çš„ author_name  
                post_info['title'],                # ä½¿ç”¨æ•°æ®åº“ä¸­çš„ title
                classification_data.get('classification'),
                classification_data.get('confidence_score'),
                classification_data.get('reasoning'),
                classification_data.get('commercial_value'),
                classification_data.get('need_ai_analysis', True),
                'dify-llm',
                '1.0',
                datetime.now()
            )
            
            with db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute(sql, params)
                    conn.commit()
                    
                    affected_rows = cursor.rowcount
                    
                    if affected_rows == 1:
                        logger.debug(f"âœ… å¸–å­åˆ†ç±»æ’å…¥æˆåŠŸ: {post_id}")
                        operation = "inserted"
                    elif affected_rows == 2:
                        logger.debug(f"ğŸ”„ å¸–å­åˆ†ç±»æ›´æ–°æˆåŠŸ: {post_id}")
                        operation = "updated"
                    else:
                        logger.debug(f"ğŸ“‹ å¸–å­åˆ†ç±»æ— å˜åŒ–: {post_id}")
                        operation = "no_change"
                    
                    return {
                        'success': True,
                        'post_id': post_id,
                        'author_id': post_info['author_id'],
                        'author_name': post_info['author_name'],
                        'operation': operation
                    }
                    
        except Exception as e:
            logger.error(f"âŒ å¸–å­åˆ†ç±»æ’å…¥å¤±è´¥: {post_id} - {e}")
            return {
                'success': False,
                'error': str(e),
                'post_id': post_id
            }
    
    def batch_insert_classifications(self, classifications: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        æ‰¹é‡æ’å…¥å¸–å­åˆ†ç±»ç»“æœ
        
        Args:
            classifications: åˆ†ç±»æ•°æ®åˆ—è¡¨
            
        Returns:
            æ‰¹é‡æ“ä½œç»“æœ
        """
        start_time = datetime.now()
        
        stored_posts = []
        failed_posts = []
        
        logger.info(f"ğŸ“ å¼€å§‹æ‰¹é‡æ’å…¥å¸–å­åˆ†ç±»: {len(classifications)} ä¸ª")
        
        for classification in classifications:
            result = self.insert_classification(classification)
            
            if result['success']:
                stored_posts.append({
                    'post_id': result['post_id'],
                    'author_id': result['author_id'],
                    'author_name': result['author_name'],
                    'operation': result['operation']
                })
            else:
                failed_posts.append({
                    'post_id': result['post_id'],
                    'error': result['error']
                })
        
        execution_time = (datetime.now() - start_time).total_seconds()
        
        result = {
            'success': len(stored_posts) > 0,
            'total_count': len(classifications),
            'stored_count': len(stored_posts),
            'failed_count': len(failed_posts),
            'stored_posts': stored_posts,
            'failed_posts': failed_posts,
            'execution_time': execution_time,
            'stored_at': datetime.now().isoformat()
        }
        
        logger.info(f"âœ… æ‰¹é‡æ’å…¥å®Œæˆ: {len(stored_posts)} æˆåŠŸ, {len(failed_posts)} å¤±è´¥, è€—æ—¶ {execution_time:.2f}s")
        
        return result
    
    def get_classification_by_post_id(self, post_id: str) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ®post_idæŸ¥è¯¢åˆ†ç±»ç»“æœ
        
        Args:
            post_id: å¸–å­ID
            
        Returns:
            åˆ†ç±»ç»“æœæˆ–None
        """
        try:
            with db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    sql = """
                    SELECT * FROM xiaohongshu_content_classification 
                    WHERE post_id = %s
                    """
                    cursor.execute(sql, (post_id,))
                    result = cursor.fetchone()
                    
                    if result:
                        return dict(result)
                    else:
                        return None
                        
        except Exception as e:
            logger.error(f"æŸ¥è¯¢å¸–å­åˆ†ç±»å¤±è´¥: {post_id} - {e}")
            return None

# åˆ›å»ºå…¨å±€å®ä¾‹
classification_repository = ClassificationRepository()
